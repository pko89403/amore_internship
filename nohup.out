2019-04-03 00:19:27.185757: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
MAX LEN :  140
MIN LEN :  0
MEAN LEN :  19.583572182833006
MED LEN :  19.0
Tokenizing Result 140 ,  3065
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
Inputs (InputLayer)             (None, 30)           0                                            
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 30, 300)      919500      Inputs[0][0]                     
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 30, 300)      919500      Inputs[0][0]                     
__________________________________________________________________________________________________
conv1d_1 (Conv1D)               (None, 29, 256)      153856      embedding_1[0][0]                
__________________________________________________________________________________________________
conv1d_2 (Conv1D)               (None, 28, 256)      230656      embedding_1[0][0]                
__________________________________________________________________________________________________
conv1d_3 (Conv1D)               (None, 27, 256)      307456      embedding_1[0][0]                
__________________________________________________________________________________________________
conv1d_4 (Conv1D)               (None, 29, 256)      153856      embedding_2[0][0]                
__________________________________________________________________________________________________
conv1d_5 (Conv1D)               (None, 28, 256)      230656      embedding_2[0][0]                
__________________________________________________________________________________________________
conv1d_6 (Conv1D)               (None, 27, 256)      307456      embedding_2[0][0]                
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 29, 256)      1024        conv1d_1[0][0]                   
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 28, 256)      1024        conv1d_2[0][0]                   
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 27, 256)      1024        conv1d_3[0][0]                   
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 29, 256)      1024        conv1d_4[0][0]                   
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 28, 256)      1024        conv1d_5[0][0]                   
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 27, 256)      1024        conv1d_6[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 29, 256)      0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 28, 256)      0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 27, 256)      0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 29, 256)      0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 28, 256)      0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 27, 256)      0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
max_pooling1d_1 (MaxPooling1D)  (None, 14, 256)      0           dropout_1[0][0]                  
__________________________________________________________________________________________________
max_pooling1d_2 (MaxPooling1D)  (None, 14, 256)      0           dropout_2[0][0]                  
__________________________________________________________________________________________________
max_pooling1d_3 (MaxPooling1D)  (None, 13, 256)      0           dropout_3[0][0]                  
__________________________________________________________________________________________________
max_pooling1d_4 (MaxPooling1D)  (None, 14, 256)      0           dropout_4[0][0]                  
__________________________________________________________________________________________________
max_pooling1d_5 (MaxPooling1D)  (None, 14, 256)      0           dropout_5[0][0]                  
__________________________________________________________________________________________________
max_pooling1d_6 (MaxPooling1D)  (None, 13, 256)      0           dropout_6[0][0]                  
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 3584)         0           max_pooling1d_1[0][0]            
__________________________________________________________________________________________________
flatten_2 (Flatten)             (None, 3584)         0           max_pooling1d_2[0][0]            
__________________________________________________________________________________________________
flatten_3 (Flatten)             (None, 3328)         0           max_pooling1d_3[0][0]            
__________________________________________________________________________________________________
flatten_4 (Flatten)             (None, 3584)         0           max_pooling1d_4[0][0]            
__________________________________________________________________________________________________
flatten_5 (Flatten)             (None, 3584)         0           max_pooling1d_5[0][0]            
__________________________________________________________________________________________________
flatten_6 (Flatten)             (None, 3328)         0           max_pooling1d_6[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 10496)        0           flatten_1[0][0]                  
                                                                 flatten_2[0][0]                  
                                                                 flatten_3[0][0]                  
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 10496)        0           flatten_4[0][0]                  
                                                                 flatten_5[0][0]                  
                                                                 flatten_6[0][0]                  
__________________________________________________________________________________________________
add_1 (Add)                     (None, 10496)        0           concatenate_1[0][0]              
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 10496)        0           add_1[0][0]                      
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 20)           209940      dropout_7[0][0]                  
==================================================================================================
Total params: 3,439,020
Trainable params: 3,435,948
Non-trainable params: 3,072
__________________________________________________________________________________________________
Train on 23864 samples, validate on 5966 samples
Epoch 1/256
 - 40s - loss: 16.1941 - acc: 0.3998 - val_loss: 9.9900 - val_acc: 0.5327
Epoch 2/256
 - 38s - loss: 7.8539 - acc: 0.5690 - val_loss: 5.5470 - val_acc: 0.6048
Epoch 3/256
 - 38s - loss: 4.4680 - acc: 0.6410 - val_loss: 3.5754 - val_acc: 0.6333
Epoch 4/256
 - 38s - loss: 2.9956 - acc: 0.6826 - val_loss: 2.7577 - val_acc: 0.6648
Epoch 5/256
 - 38s - loss: 2.3026 - acc: 0.7067 - val_loss: 2.2085 - val_acc: 0.6971
Epoch 6/256
 - 38s - loss: 1.9429 - acc: 0.7318 - val_loss: 2.3813 - val_acc: 0.6483
Epoch 7/256
 - 38s - loss: 1.7979 - acc: 0.7427 - val_loss: 2.1476 - val_acc: 0.6596
Epoch 8/256
 - 38s - loss: 1.7099 - acc: 0.7524 - val_loss: 2.0167 - val_acc: 0.6921
Epoch 9/256
 - 38s - loss: 1.6312 - acc: 0.7621 - val_loss: 2.0386 - val_acc: 0.6946
Epoch 10/256
 - 38s - loss: 1.5573 - acc: 0.7734 - val_loss: 2.0681 - val_acc: 0.6785
Epoch 11/256
 - 38s - loss: 1.4859 - acc: 0.7810 - val_loss: 2.0294 - val_acc: 0.6995
Epoch 12/256
 - 38s - loss: 1.4560 - acc: 0.7902 - val_loss: 2.0869 - val_acc: 0.6760
Epoch 13/256
 - 38s - loss: 1.4694 - acc: 0.7899 - val_loss: 2.0822 - val_acc: 0.6894
Epoch 14/256
 - 38s - loss: 1.4702 - acc: 0.7981 - val_loss: 2.1457 - val_acc: 0.6889
Epoch 15/256
 - 38s - loss: 1.4603 - acc: 0.7959 - val_loss: 1.8642 - val_acc: 0.7239
Epoch 16/256
 - 38s - loss: 1.4311 - acc: 0.8015 - val_loss: 2.0906 - val_acc: 0.6864
Epoch 17/256
 - 38s - loss: 1.4141 - acc: 0.8042 - val_loss: 1.9965 - val_acc: 0.7117
Epoch 18/256
 - 38s - loss: 1.4267 - acc: 0.8031 - val_loss: 2.1022 - val_acc: 0.6969
Epoch 19/256
 - 38s - loss: 1.3800 - acc: 0.8118 - val_loss: 2.0891 - val_acc: 0.6891
Epoch 20/256
 - 38s - loss: 1.3510 - acc: 0.8168 - val_loss: 2.0876 - val_acc: 0.6971
Epoch 21/256
 - 38s - loss: 1.3317 - acc: 0.8180 - val_loss: 2.0459 - val_acc: 0.7037
Epoch 22/256
 - 38s - loss: 1.3135 - acc: 0.8209 - val_loss: 2.1395 - val_acc: 0.6975
Epoch 23/256
 - 38s - loss: 1.3014 - acc: 0.8275 - val_loss: 2.0285 - val_acc: 0.7134
Epoch 24/256
 - 38s - loss: 1.2659 - acc: 0.8277 - val_loss: 2.2496 - val_acc: 0.6681
Epoch 25/256
 - 38s - loss: 1.2691 - acc: 0.8277 - val_loss: 2.0137 - val_acc: 0.7130

  32/9944 [..............................] - ETA: 4s
 160/9944 [..............................] - ETA: 4s
 288/9944 [..............................] - ETA: 4s
 416/9944 [>.............................] - ETA: 4s
 544/9944 [>.............................] - ETA: 4s
 672/9944 [=>............................] - ETA: 4s
 800/9944 [=>............................] - ETA: 4s
 928/9944 [=>............................] - ETA: 4s
1056/9944 [==>...........................] - ETA: 4s
1184/9944 [==>...........................] - ETA: 4s
1312/9944 [==>...........................] - ETA: 4s
1440/9944 [===>..........................] - ETA: 4s
1568/9944 [===>..........................] - ETA: 4s
1696/9944 [====>.........................] - ETA: 4s
1824/9944 [====>.........................] - ETA: 3s
1952/9944 [====>.........................] - ETA: 3s
2080/9944 [=====>........................] - ETA: 3s
2208/9944 [=====>........................] - ETA: 3s
2336/9944 [======>.......................] - ETA: 3s
2464/9944 [======>.......................] - ETA: 3s
2592/9944 [======>.......................] - ETA: 3s
2720/9944 [=======>......................] - ETA: 3s
2848/9944 [=======>......................] - ETA: 3s
2976/9944 [=======>......................] - ETA: 3s
3104/9944 [========>.....................] - ETA: 3s
3232/9944 [========>.....................] - ETA: 3s
3360/9944 [=========>....................] - ETA: 3s
3488/9944 [=========>....................] - ETA: 3s
3616/9944 [=========>....................] - ETA: 3s
3744/9944 [==========>...................] - ETA: 3s
3872/9944 [==========>...................] - ETA: 2s
4000/9944 [===========>..................] - ETA: 2s
4128/9944 [===========>..................] - ETA: 2s
4256/9944 [===========>..................] - ETA: 2s
4384/9944 [============>.................] - ETA: 2s
4512/9944 [============>.................] - ETA: 2s
4640/9944 [============>.................] - ETA: 2s
4768/9944 [=============>................] - ETA: 2s
4896/9944 [=============>................] - ETA: 2s
5024/9944 [==============>...............] - ETA: 2s
5152/9944 [==============>...............] - ETA: 2s
5280/9944 [==============>...............] - ETA: 2s
5408/9944 [===============>..............] - ETA: 2s
5536/9944 [===============>..............] - ETA: 2s
5664/9944 [================>.............] - ETA: 2s
5792/9944 [================>.............] - ETA: 2s
5920/9944 [================>.............] - ETA: 1s
6048/9944 [=================>............] - ETA: 1s
6176/9944 [=================>............] - ETA: 1s
6272/9944 [=================>............] - ETA: 1s
6400/9944 [==================>...........] - ETA: 1s
6496/9944 [==================>...........] - ETA: 1s
6624/9944 [==================>...........] - ETA: 1s
6720/9944 [===================>..........] - ETA: 1s
6848/9944 [===================>..........] - ETA: 1s
6944/9944 [===================>..........] - ETA: 1s
7072/9944 [====================>.........] - ETA: 1s
7200/9944 [====================>.........] - ETA: 1s
7328/9944 [=====================>........] - ETA: 1s
7456/9944 [=====================>........] - ETA: 1s
7584/9944 [=====================>........] - ETA: 1s
7712/9944 [======================>.......] - ETA: 1s
7840/9944 [======================>.......] - ETA: 1s
7968/9944 [=======================>......] - ETA: 0s
8096/9944 [=======================>......] - ETA: 0s
8224/9944 [=======================>......] - ETA: 0s
8320/9944 [========================>.....] - ETA: 0s
8448/9944 [========================>.....] - ETA: 0s
8576/9944 [========================>.....] - ETA: 0s
8704/9944 [=========================>....] - ETA: 0s
8800/9944 [=========================>....] - ETA: 0s
8928/9944 [=========================>....] - ETA: 0s
9056/9944 [==========================>...] - ETA: 0s
9184/9944 [==========================>...] - ETA: 0s
9312/9944 [===========================>..] - ETA: 0s
9440/9944 [===========================>..] - ETA: 0s
9568/9944 [===========================>..] - ETA: 0s
9696/9944 [============================>.] - ETA: 0s
9824/9944 [============================>.] - ETA: 0s
9944/9944 [==============================] - 5s 500us/step
Using TensorFlow backend.
Test loss:  2.0024598728526724
Test Accuracy:  0.7133950121155307
